{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Using Naive Bayes classifier described in this chapter, and any features you can think of, build the best name gender classifier you can. Begin by splitting the Names Corpus into three subsets: 500 words for the test set, 500 words for the dev-test set, and the remaining 6900 words for the training set. Then, starting with the example name gender classifier, make incremental improvements. Use the dev-test set to check your progress. Once you are satisfied with your classifier, check its final performance on the test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_names = ([(name, 'male') for name in names.words('male.txt')] +\n",
    "   [(name, 'female') for name in names.words('female.txt')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7944"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labeled_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(labeled_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gender_features(word):\n",
    "    return {'suffix1': word[-1:],\n",
    "            'suffix2': word[-2:]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_names = labeled_names[1000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "devtest_names = labeled_names[500:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_names = labeled_names[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = [(gender_features(n), gender) for (n, gender) in train_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "devtest_set = [(gender_features(n), gender) for (n, gender) in devtest_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = [(gender_features(n), gender) for (n, gender) in test_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = nltk.NaiveBayesClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.782\n"
     ]
    }
   ],
   "source": [
    "print(nltk.classify.accuracy(classifier, devtest_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (name, tag) in devtest_names:\n",
    "    guess = classifier.classify(gender_features(name))\n",
    "    if guess != tag:\n",
    "        errors.append( (tag, guess, name) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct=female   guess=male     name=Allyson                       \n",
      "correct=female   guess=male     name=Alyss                         \n",
      "correct=female   guess=male     name=Arabel                        \n",
      "correct=female   guess=male     name=Ardis                         \n",
      "correct=female   guess=male     name=Bird                          \n",
      "correct=female   guess=male     name=Bliss                         \n",
      "correct=female   guess=male     name=Britaney                      \n",
      "correct=female   guess=male     name=Cam                           \n",
      "correct=female   guess=male     name=Carey                         \n",
      "correct=female   guess=male     name=Caroljean                     \n",
      "correct=female   guess=male     name=Chriss                        \n",
      "correct=female   guess=male     name=Christan                      \n",
      "correct=female   guess=male     name=Consuelo                      \n",
      "correct=female   guess=male     name=Courtenay                     \n",
      "correct=female   guess=male     name=Cynthy                        \n",
      "correct=female   guess=male     name=Dallas                        \n",
      "correct=female   guess=male     name=Daniel                        \n",
      "correct=female   guess=male     name=Dawn                          \n",
      "correct=female   guess=male     name=Dionis                        \n",
      "correct=female   guess=male     name=Easter                        \n",
      "correct=female   guess=male     name=Eden                          \n",
      "correct=female   guess=male     name=Eilis                         \n",
      "correct=female   guess=male     name=Ester                         \n",
      "correct=female   guess=male     name=Fanchon                       \n",
      "correct=female   guess=male     name=Gabriel                       \n",
      "correct=female   guess=male     name=Gaynor                        \n",
      "correct=female   guess=male     name=Gretal                        \n",
      "correct=female   guess=male     name=Gwendolen                     \n",
      "correct=female   guess=male     name=Harriet                       \n",
      "correct=female   guess=male     name=Ibby                          \n",
      "correct=female   guess=male     name=Jaquelin                      \n",
      "correct=female   guess=male     name=Jordan                        \n",
      "correct=female   guess=male     name=Jorry                         \n",
      "correct=female   guess=male     name=Karen                         \n",
      "correct=female   guess=male     name=Karry                         \n",
      "correct=female   guess=male     name=Katlin                        \n",
      "correct=female   guess=male     name=Kelcey                        \n",
      "correct=female   guess=male     name=Koral                         \n",
      "correct=female   guess=male     name=Lamb                          \n",
      "correct=female   guess=male     name=Leanor                        \n",
      "correct=female   guess=male     name=Mabel                         \n",
      "correct=female   guess=male     name=Mair                          \n",
      "correct=female   guess=male     name=Marget                        \n",
      "correct=female   guess=male     name=Margot                        \n",
      "correct=female   guess=male     name=Margret                       \n",
      "correct=female   guess=male     name=Mariel                        \n",
      "correct=female   guess=male     name=Marjory                       \n",
      "correct=female   guess=male     name=Marney                        \n",
      "correct=female   guess=male     name=Meg                           \n",
      "correct=female   guess=male     name=Meghan                        \n",
      "correct=female   guess=male     name=Micky                         \n",
      "correct=female   guess=male     name=Miran                         \n",
      "correct=female   guess=male     name=Opal                          \n",
      "correct=female   guess=male     name=Philis                        \n",
      "correct=female   guess=male     name=Piper                         \n",
      "correct=female   guess=male     name=Raychel                       \n",
      "correct=female   guess=male     name=Robinet                       \n",
      "correct=female   guess=male     name=Rosamond                      \n",
      "correct=female   guess=male     name=Tamiko                        \n",
      "correct=female   guess=male     name=Tomiko                        \n",
      "correct=female   guess=male     name=Viv                           \n",
      "correct=female   guess=male     name=Yoshiko                       \n",
      "correct=male     guess=female   name=Avi                           \n",
      "correct=male     guess=female   name=Barty                         \n",
      "correct=male     guess=female   name=Brady                         \n",
      "correct=male     guess=female   name=Chance                        \n",
      "correct=male     guess=female   name=Clare                         \n",
      "correct=male     guess=female   name=Clarence                      \n",
      "correct=male     guess=female   name=Clive                         \n",
      "correct=male     guess=female   name=Davie                         \n",
      "correct=male     guess=female   name=Deryl                         \n",
      "correct=male     guess=female   name=Doyle                         \n",
      "correct=male     guess=female   name=Duffie                        \n",
      "correct=male     guess=female   name=Gerri                         \n",
      "correct=male     guess=female   name=Giffie                        \n",
      "correct=male     guess=female   name=Hale                          \n",
      "correct=male     guess=female   name=Herbie                        \n",
      "correct=male     guess=female   name=Iggie                         \n",
      "correct=male     guess=female   name=Isaiah                        \n",
      "correct=male     guess=female   name=Jeremie                       \n",
      "correct=male     guess=female   name=Jodie                         \n",
      "correct=male     guess=female   name=Jody                          \n",
      "correct=male     guess=female   name=Johny                         \n",
      "correct=male     guess=female   name=Keene                         \n",
      "correct=male     guess=female   name=Luce                          \n",
      "correct=male     guess=female   name=Lyn                           \n",
      "correct=male     guess=female   name=Martainn                      \n",
      "correct=male     guess=female   name=Montague                      \n",
      "correct=male     guess=female   name=Neville                       \n",
      "correct=male     guess=female   name=Noah                          \n",
      "correct=male     guess=female   name=Penn                          \n",
      "correct=male     guess=female   name=Rice                          \n",
      "correct=male     guess=female   name=Rickie                        \n",
      "correct=male     guess=female   name=Ritchie                       \n",
      "correct=male     guess=female   name=Roni                          \n",
      "correct=male     guess=female   name=Royce                         \n",
      "correct=male     guess=female   name=Rustie                        \n",
      "correct=male     guess=female   name=Sibyl                         \n",
      "correct=male     guess=female   name=Sully                         \n",
      "correct=male     guess=female   name=Timmy                         \n",
      "correct=male     guess=female   name=Torre                         \n",
      "correct=male     guess=female   name=Uriah                         \n",
      "correct=male     guess=female   name=Verne                         \n",
      "correct=male     guess=female   name=Willie                        \n"
     ]
    }
   ],
   "source": [
    "for (tag, guess, name) in sorted(errors):\n",
    "    print('correct={:<8} guess={:<8} name={:<30}'.format(tag, guess, name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "104"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresets = [(gender_features(n), gender) for (n, gender) in labeled_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = featuresets[500:], featuresets[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = nltk.NaiveBayesClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.798\n"
     ]
    }
   ],
   "source": [
    "print(nltk.classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gender_features2(name):\n",
    "    features2 = {}\n",
    "    features2[\"first_letter\"] = name[0].lower()\n",
    "    features2[\"suffix1\"] = name[-1:].lower()\n",
    "    features2[\"suffix2\"] = name[-2:].lower()\n",
    "    for letter in 'abcdefghijklmnopqrstuvwxyz':\n",
    "        features2[\"count({})\".format(letter)] = name.lower().count(letter)\n",
    "    return features2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = [(gender_features2(n), gender) for (n, gender) in train_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "devtest_set = [(gender_features2(n), gender) for (n, gender) in devtest_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = nltk.NaiveBayesClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.79\n"
     ]
    }
   ],
   "source": [
    "print(nltk.classify.accuracy(classifier, devtest_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors2 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (name, tag) in devtest_names:\n",
    "    guess = classifier.classify(gender_features2(name))\n",
    "    if guess != tag:\n",
    "        errors.append( (tag, guess, name) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (tag, guess, name) in sorted(errors2):\n",
    "    print('correct={:<8} guess={:<8} name={:<30}'.format(tag, guess, name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(errors2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresets = [(gender_features2(n), gender) for (n, gender) in labeled_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = featuresets[500:], featuresets[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = nltk.NaiveBayesClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.812\n"
     ]
    }
   ],
   "source": [
    "print(nltk.classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Using the movie review document classifier discussed in Chapter 6- Section 1.3 ( constructing a list of the 2500 most frequent words as features and use the first 150 documents as the test dataset) , generate a list of the 10 features that the classifier finds to be most informative. Can you explain why these particular features are informative? Do you find any of them surprising?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import movie_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [(list(movie_reviews.words(fileid)), category)\n",
    "            for category in movie_reviews.categories()\n",
    "            for fileid in movie_reviews.fileids(category)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = nltk.FreqDist(w.lower() for w in movie_reviews.words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_features = list(all_words)[:2500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "def document_features(document):\n",
    "    document_words = set(document)\n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        features['contains({})'.format(word)] = (word in document_words)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresets = [(document_features(d), c) for (d,c) in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = featuresets[150:], featuresets[:150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = nltk.NaiveBayesClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8666666666666667\n"
     ]
    }
   ],
   "source": [
    "print(nltk.classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "        contains(turkey) = True              neg : pos    =     12.0 : 1.0\n",
      "        contains(annual) = True              pos : neg    =      9.8 : 1.0\n",
      "       contains(frances) = True              pos : neg    =      9.1 : 1.0\n",
      " contains(unimaginative) = True              neg : pos    =      7.6 : 1.0\n",
      "        contains(regard) = True              pos : neg    =      7.1 : 1.0\n",
      "        contains(suvari) = True              neg : pos    =      6.9 : 1.0\n",
      "          contains(mold) = True              neg : pos    =      6.9 : 1.0\n",
      "          contains(mena) = True              neg : pos    =      6.9 : 1.0\n",
      "    contains(schumacher) = True              neg : pos    =      6.5 : 1.0\n",
      "       contains(singers) = True              pos : neg    =      6.4 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The above code line generates the 10 most informative features. Those particular features are informative because most of the words are not neutral but with positive or negative meanings so we may use them to evaluate if the comments are positive or not.The \"turkey\" and \"schumacher\" surprised me because they indicate negative context considering they are just noun. So I would assume they have different meanings in spoken english or slang."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Select one of the classification tasks described in this chapter, such as name gender detection, document classification, part-of-speech tagging, or dialog act classification. Using the same training and test data, and the same feature extractor, build three classifiers for the task: a decision tree, a naive Bayes classifier, and a  Maximum Entropy classifier. Compare the performance of the three classifiers on your selected task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = nltk.FreqDist(w.lower() for w in movie_reviews.words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_features = list(all_words)[:2500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "def document_features(document):\n",
    "    document_words = set(document)\n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        features['contains({})'.format(word)] = (word in document_words)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresets = [(document_features(d), c) for (d,c) in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = featuresets[150:], featuresets[:150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier1 = nltk.NaiveBayesClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier2 = nltk.DecisionTreeClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ==> Training (100 iterations)\n",
      "\n",
      "      Iteration    Log Likelihood    Accuracy\n",
      "      ---------------------------------------\n",
      "             1          -0.69315        0.497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gabriella\\Anaconda3\\lib\\site-packages\\nltk\\classify\\maxent.py:1392: RuntimeWarning: overflow encountered in power\n",
      "  exp_nf_delta = 2 ** nf_delta\n",
      "C:\\Users\\Gabriella\\Anaconda3\\lib\\site-packages\\nltk\\classify\\maxent.py:1394: RuntimeWarning: invalid value encountered in multiply\n",
      "  sum1 = numpy.sum(exp_nf_delta * A, axis=0)\n",
      "C:\\Users\\Gabriella\\Anaconda3\\lib\\site-packages\\nltk\\classify\\maxent.py:1395: RuntimeWarning: invalid value encountered in multiply\n",
      "  sum2 = numpy.sum(nf_exp_nf_delta * A, axis=0)\n",
      "C:\\Users\\Gabriella\\Anaconda3\\lib\\site-packages\\nltk\\classify\\maxent.py:1402: RuntimeWarning: invalid value encountered in true_divide\n",
      "  deltas -= (ffreq_empirical - sum1) / -sum2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Final               nan        0.503\n"
     ]
    }
   ],
   "source": [
    "classifier3 = nltk.MaxentClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8666666666666667\n"
     ]
    }
   ],
   "source": [
    "print(nltk.classify.accuracy(classifier1, test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.64\n"
     ]
    }
   ],
   "source": [
    "print(nltk.classify.accuracy(classifier2, test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.46\n"
     ]
    }
   ],
   "source": [
    "print(nltk.classify.accuracy(classifier3, test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Identify the NPS Chat Corpus, which was demonstrated in Chapter 2, consists of over 15,000 posts from instant messaging sessions. These posts have all been labeled with one of 15 dialogue act types, such as \"Statement,\" \"Emotion,\" \"ynQuestion\", and \"Continuer.\" We can therefore use this data to build a classifier that can identify the dialogue act types for new instant messaging posts. Build a simple feature extractor that checks what words the post contains. Construct the training and testing data by applying the feature extractor to each post and create a Na√Øve Bayes classifier. Please print the accuracy of this classifier. We use the first 15,000 messages from these instant messages as our dataset and use 8% data as our test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts = nltk.corpus.nps_chat.xml_posts()[:15000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dialogue_act_features(post):\n",
    "    features = {}\n",
    "    for word in nltk.word_tokenize(post):\n",
    "        features['contains({})'.format(word.lower())] = True\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresets = [(dialogue_act_features(post.text), post.get('class'))\n",
    "              for post in posts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = int(len(featuresets) * 0.08)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = featuresets[size:], featuresets[:size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = nltk.NaiveBayesClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.676923076923077\n"
     ]
    }
   ],
   "source": [
    "print(nltk.classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 5.Given the following confusion matrix, please calculate: a) Accuracy Rate; b) Precision; c) Recall; d) F-Measure.\n",
    "\n",
    "\tNo\tYes\n",
    "No\t104\t33\n",
    "Yes\t13\t50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observations 200\n"
     ]
    }
   ],
   "source": [
    "# a) Accuracy Rate\n",
    "observations = 104 + 33 + 13 + 50\n",
    "print(\"Number of observations\", observations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy rate 0.77\n"
     ]
    }
   ],
   "source": [
    "accuracy = (104 + 50) / 200\n",
    "print(\"The accuracy rate\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision 0.7936507936507936\n"
     ]
    }
   ],
   "source": [
    "# b) Precision\n",
    "precision = 50 / (50 + 13)\n",
    "print(\"Precision\", precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall 0.6024096385542169\n"
     ]
    }
   ],
   "source": [
    "# c) Recall\n",
    "recall = 50 / (50 + 33)\n",
    "print(\"Recall\", recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-Measure 0.6849315068493151\n"
     ]
    }
   ],
   "source": [
    "# d) F-Measure\n",
    "F = (2 * precision * recall) / (precision + recall)\n",
    "print(\"F-Measure\", F)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Write a tag pattern to match noun phrases containing plural head nouns in the following sentence: \"Many researchers discussed this project for two weeks.\" Try to do this by generalizing the tag pattern that handled singular noun phrases too. Please 1) pos-tag this sentence 2) write a tag pattern (i.e. grammar); 3) use RegexpParser to parse the sentence and 4) print out the result containing NP (noun phrases)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"Many researchers discussed this project for two weeks.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1)\n",
    "def ie_preprocess(document):\n",
    "    sentences = nltk.sent_tokenize(document)\n",
    "    sentences = [nltk.word_tokenize(sent) for sent in sentences]\n",
    "    sentences = [nltk.pos_tag(sent) for sent in sentences]\n",
    "    print(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('Many', 'JJ'), ('researchers', 'NNS'), ('discussed', 'VBD'), ('this', 'DT'), ('project', 'NN'), ('for', 'IN'), ('two', 'CD'), ('weeks', 'NNS'), ('.', '.')]]\n"
     ]
    }
   ],
   "source": [
    "ie_preprocess(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = [('Many', 'JJ'), ('researchers', 'NNS'), ('discussed', 'VBD'), ('this', 'DT'), ('project', 'NN'), ('for', 'IN'), ('two', 'CD'), ('weeks', 'NNS'), ('.', '.')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2)\n",
    "grammar = \"NP: {<DT>?<JJ>*<NNS|NN>}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3)\n",
    "cp = nltk.RegexpParser(grammar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4)\n",
    "result = cp.parse(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP Many/JJ researchers/NNS)\n",
      "  discussed/VBD\n",
      "  (NP this/DT project/NN)\n",
      "  for/IN\n",
      "  two/CD\n",
      "  (NP weeks/NNS)\n",
      "  ./.)\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Write a tag pattern to cover noun phrases that contain gerunds, e.g. \"the/DT receiving/VBG end/NN\", \"assistant/NN managing/VBG editor/NN\". Add these patterns to the grammar, one per line. Test your work using some tagged sentences of your own devising."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar = r\"\"\"\n",
    "  NP: {<DT>?<VBG>*<NN>+}\n",
    "      {<DT>?<JJ>*<NNS|NN>} \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"The testing end engineer monitoring the process.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ie_preprocess(document):\n",
    "    sentences = nltk.sent_tokenize(document)\n",
    "    sentences = [nltk.word_tokenize(sent) for sent in sentences]\n",
    "    sentences = [nltk.pos_tag(sent) for sent in sentences]\n",
    "    print(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('The', 'DT'), ('testing', 'VBG'), ('end', 'NN'), ('engineer', 'NN'), ('monitoring', 'VBG'), ('the', 'DT'), ('process', 'NN'), ('.', '.')]]\n"
     ]
    }
   ],
   "source": [
    "ie_preprocess(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = [('The', 'DT'), ('testing', 'VBG'), ('end', 'NN'), ('engineer', 'NN'), ('monitoring', 'VBG'), ('the', 'DT'), ('process', 'NN'), ('.', '.')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp = nltk.RegexpParser(grammar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = cp.parse(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP The/DT testing/VBG end/NN engineer/NN)\n",
      "  monitoring/VBG\n",
      "  (NP the/DT process/NN)\n",
      "  ./.)\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Use the Brown Corpus and the cascaded chunkers that has patterns for noun phrases, prepositional phrases, verb phrases, and clauses to print out all the verb phrases in the Brown corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_chunks(grammer):\n",
    "    brown = nltk.corpus.brown\n",
    "    cp=nltk.RegexpParser(grammer)\n",
    "    for sent in brown.tagged_sents():\n",
    "        tree = cp.parse(sent)\n",
    "        for subtree in tree.subtrees():\n",
    "            if subtree.label() == 'VP': print(subtree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar = r\"\"\"\n",
    "  NP: {<DT|JJ|NN.*>+}          \n",
    "  PP: {<IN><NP>}            \n",
    "  VP: {<VB.*><NP|PP|CLAUSE>+$} \n",
    "  CLAUSE: {<NP><VP>}           \n",
    "  \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(VP Ask/VB-HL (NP jail/NN-HL deputies/NNS-HL))\n",
      "(VP revolving/VBG-HL (NP fund/NN-HL))\n",
      "(VP Issue/VB-HL (NP jury/NN-HL subpoenas/NNS-HL))\n",
      "(VP Nursing/VBG-HL (NP home/NN-HL care/NN-HL))\n",
      "(VP pay/VB-HL (NP doctors/NNS-HL))\n",
      "(VP nursing/VBG-HL (NP homes/NNS))\n",
      "(VP Asks/VBZ-HL (NP research/NN-HL funds/NNS-HL))\n",
      "(VP Regrets/VBZ-HL (NP attack/NN-HL))\n",
      "(VP Decries/VBZ-HL (NP joblessness/NN-HL))\n",
      "(VP Underlying/VBG-HL (NP concern/NN-HL))\n",
      "(VP bar/VB-HL (NP vehicles/NNS-HL))\n",
      "(VP loses/VBZ-HL (NP pace/NN-HL))\n",
      "(VP hits/VBZ-HL (NP homer/NN-HL))\n",
      "(VP attend/VB-HL (NP races/NNS-HL))\n",
      "(VP follows/VBZ-HL (NP ceremonies/NNS-HL))\n",
      "(VP Noted/VBN-HL (NP artist/NN-HL))\n",
      "(VP Cites/VBZ-HL (NP discrepancies/NNS-HL))\n",
      "(VP calls/VBZ-HL (NP police/NNS-HL))\n",
      "(VP held/VBN-HL (NP key/NN-HL))\n",
      "(VP grant/VB-HL (NP bail/NN-HL))\n",
      "(VP Held/VBD-HL (NP candle/NN-HL))\n",
      "(VP Expresses/VBZ-HL (NP thanks/NNS-HL))\n",
      "(VP Gets/VBZ-HL (NP car/NN-HL number/NN-HL))\n",
      "(VP Attacks/VBZ-HL (NP officer/NN-HL))\n",
      "(VP oks/VBZ-HL (NP pact/NN-HL))\n",
      "(VP report/VB-HL (NP gains/NNS-HL))\n",
      "(VP Pulling/VBG-HL (NP strings/NNS-HL))\n",
      "(VP United/VBN-TL-HL (NP States/NNS-TL-HL defense/NN-HL))\n",
      "(VP Betting/VBG-HL (NP men/NNS-HL))\n",
      "(VP brings/VBZ-HL (NP numbness/NN-HL))\n",
      "(VP Questions/VBZ-HL (NP shelters/NNS-HL))\n",
      "(VP Marketing/VBG-HL (NP meat/NN-HL))\n",
      "(VP Taxing/VBG-HL (NP improvements/NNS-HL))\n",
      "(VP Praises/VBZ-HL (NP exhibit/NN-HL))\n",
      "(VP aid/VB (NP international/JJ law/NN))\n",
      "(VP retarded/VBN-HL (NP children/NNS-HL))\n",
      "(VP tormented/VBN-HL (NP span/NN-HL))\n",
      "(VP dashed/VBN-HL (NP hope/NN-HL))\n",
      "(VP open/VB-HL (NP program/NN-HL))\n",
      "(VP Fleeting/VBG-HL (NP glimpse/NN-HL))\n",
      "(VP fragmented/VBN-HL (NP Society/NN-TL-HL))\n",
      "(VP locking/VBG-HL (NP bars/NNS-HL))\n",
      "(VP fire/VB (NP standard/JJ))\n",
      "(VP Canned/VBN-HL (NP cocktail/NN-HL frankfurters/NNS-HL))\n",
      "(VP whipped/VBN (NP Salt/NN Paprika/NN))\n",
      "(VP Barbecued/VBN-HL (NP frankfurters/NNS-HL))\n",
      "(VP Changing/VBG-HL (NP colors/NNS-HL))\n",
      "(VP Measuring/VBG-HL (NP armhole/NN-HL))\n",
      "(VP Backstitching/VBG-HL (NP seam/NN-HL))\n",
      "(VP Weaving/VBG-HL (NP seam/NN-HL))\n",
      "(VP drilling/VBG-HL (NP tools/NNS-HL))\n",
      "(VP drilling/VBG-HL (NP operations/NNS-HL))\n",
      "(VP Adjoining/VBG-HL (NP areas/NNS-HL))\n",
      "(VP chinning/VBG-HL (NP bar/NN-HL))\n",
      "(VP fattening/VBG-HL (NP rations/NNS-HL))\n",
      "(VP marketing/VBG-HL (NP methods/NNS-HL))\n",
      "(VP marketing/VBG-HL (NP management/NN-HL))\n",
      "(VP feeding/VBG-HL (NP facilities/NNS-HL))\n",
      "(VP Paid/VBN-HL (NP vacations/NNS-HL))\n",
      "(VP Eating/VBG-HL (NP facilities/NNS-HL))\n",
      "(VP farming/VBG-HL (NP methods/NNS-HL))\n",
      "(VP Nourishing/VBG (NP meals/NNS))\n",
      "(VP save/VB-HL (NP teeth/NNS-HL))\n",
      "(VP helps/VBZ-HL (NP families/NNS-HL))\n",
      "(VP Printed/VBN-HL (NP material/NN-HL))\n",
      "(VP Printed/VBN-HL (NP material/NN-HL))\n",
      "(VP Printed/VBN-HL (NP material/NN-HL))\n",
      "(VP Printed/VBN-HL (NP material/NN-HL))\n",
      "(VP planning/VBG-HL (NP process/NN-HL))\n",
      "(VP applying/VBG-HL (NP conditions/NNS-HL))\n",
      "(VP Encouraging/VBG-HL (NP self-help/NN-HL))\n",
      "(VP stressing/VBG-HL (NP self-help/NN-HL))\n",
      "(VP nearing/VBG-HL (NP self-sufficiency/NN-HL))\n",
      "(VP Advertising/VBG-HL (NP program/NN-HL))\n",
      "(VP Planning/VBG-HL (NP division/NN-HL))\n",
      "(VP financing/VBG-HL (NP adjustments/NNS-HL))\n",
      "(VP distributing/VBG-HL (NP funds/NNS-HL))\n",
      "(VP Matching/VBG-HL (NP requirements/NNS-HL))\n",
      "(VP prepared/VBN (NP shelter/NN))\n",
      "(VP Increased/VBN-HL (NP efficiency/NN-HL))\n",
      "(VP shifting/VBG-HL (NP styles/NNS-HL))\n",
      "(VP broadcasting/VBG-HL (NP station/NN-HL))\n",
      "(VP cleaning/VBG-HL (NP process/NN-HL))\n",
      "(VP frozen/VBN-HL (NP sections/NNS-HL))\n",
      "(VP Staining/VBG-HL (NP technique/NN-HL))\n",
      "(VP Concluding/VBG-HL (NP remarks/NNS-HL))\n",
      "(VP modernizing/VBG-HL (NP societies/NNS-HL))\n",
      "(VP teaching/VBG-HL (NP methods/NNS-HL))\n",
      "(VP teaching/VBG-HL (NP methods/NNS-HL))\n",
      "(VP bargaining/VBG-HL (NP issues/NNS-HL))\n",
      "(VP\n",
      "  selecting/VBG-HL\n",
      "  (NP mail/NN-HL questionnaire/NN-HL method/NN-HL))\n",
      "(VP mailing/VBG-HL (NP lists/NNS-HL))\n",
      "(VP distributed/VBN-HL (NP cost/NN-HL analysis/NN-HL))\n",
      "(VP define/VB-HL (NP input/output/NN-HL control/NN-HL system/NN-HL))\n",
      "(VP related/VBN-HL (NP materials/NNS-HL))\n",
      "(VP ionizing/VBG-HL (NP radiation/NN-HL))\n",
      "(VP seen/VBN (NP that/DT Af/NN))\n",
      "(VP\n",
      "  Chipping/VBG\n",
      "  (NP mechanism/NN)\n",
      "  (PP of/IN (NP cohesive/JJ failure/NN)))\n",
      "(VP cracking/VBG-HL (NP mechanism/NN-HL))\n",
      "(VP Processing/VBG-HL (NP urethanes/NNS-HL))\n",
      "(VP coupled/VBN-HL (NP image/NN-HL intensifiers/NNS-HL))\n",
      "(VP following/VBG (NP morning/NN))\n",
      "(VP whining/VBG (NP voice/NN))\n",
      "(VP convinced/VBN (PP of/IN (NP that/DT)))\n"
     ]
    }
   ],
   "source": [
    "find_chunks(grammar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. The bigram chunker scores about 90% accuracy. Study its errors and try to work out why it doesn't get 100% accuracy. Experiment with trigram chunking. Are you able to improve the performance any more?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import conll2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sents = conll2000.chunked_sents('test.txt', chunk_types=['NP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sents = conll2000.chunked_sents('train.txt', chunk_types=['NP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BigramChunker(nltk.ChunkParserI):\n",
    "    def __init__(self, train_sents): \n",
    "        train_data = [[(t,c) for w,t,c in nltk.chunk.tree2conlltags(sent)]\n",
    "                      for sent in train_sents]\n",
    "        self.tagger = nltk.BigramTagger(train_data)\n",
    "    def parse(self, sentence): \n",
    "        pos_tags = [pos for (word,pos) in sentence]\n",
    "        tagged_pos_tags = self.tagger.tag(pos_tags)\n",
    "        chunktags = [chunktag for (pos, chunktag) in tagged_pos_tags]\n",
    "        conlltags = [(word, pos, chunktag) for ((word,pos),chunktag)\n",
    "                     in zip(sentence, chunktags)]\n",
    "        return nltk.chunk.conlltags2tree(conlltags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChunkParse score:\n",
      "    IOB Accuracy:  93.3%%\n",
      "    Precision:     82.3%%\n",
      "    Recall:        86.8%%\n",
      "    F-Measure:     84.5%%\n"
     ]
    }
   ],
   "source": [
    "bigram_chunker = BigramChunker(train_sents)\n",
    "print(bigram_chunker.evaluate(test_sents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrigramChunker(nltk.ChunkParserI):\n",
    "    def __init__(self, train_sents): \n",
    "        train_data = [[(t,c) for w,t,c in nltk.chunk.tree2conlltags(sent)]\n",
    "                      for sent in train_sents]\n",
    "        self.tagger = nltk.TrigramTagger(train_data)\n",
    "    def parse(self, sentence): \n",
    "        pos_tags = [pos for (word,pos) in sentence]\n",
    "        tagged_pos_tags = self.tagger.tag(pos_tags)\n",
    "        chunktags = [chunktag for (pos, chunktag) in tagged_pos_tags]\n",
    "        conlltags = [(word, pos, chunktag) for ((word,pos),chunktag)\n",
    "                     in zip(sentence, chunktags)]\n",
    "        return nltk.chunk.conlltags2tree(conlltags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChunkParse score:\n",
      "    IOB Accuracy:  93.3%%\n",
      "    Precision:     82.5%%\n",
      "    Recall:        86.8%%\n",
      "    F-Measure:     84.6%%\n"
     ]
    }
   ],
   "source": [
    "trigram_chunker = TrigramChunker(train_sents)\n",
    "print(trigram_chunker.evaluate(test_sents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The bigram tagger manages to tag every word in a sentence it saw during training, but does badly on an unseen sentence. As soon as it encounters a new word, it is unable to assign a tag. It cannot tag the following word, even if it was seen during training, simply because it never saw it during training with none tag on the previous word. Consequently, the tagger fails to tag the rest of the sentence. That is the reason why it doesn't get 100% accuracy. Seen from the trigram chunking, the accuracy performance could not be improved. They probably need more data to train in order to give better results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Explore the Brown Corpus to print out all the FACILITIES (one of the commonly used types of name entities)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(FACILITY Raymondville/NP)\n",
      "(FACILITY White/JJ-TL)\n",
      "(FACILITY White/JJ-TL)\n",
      "(FACILITY White/JJ-TL)\n",
      "(FACILITY White/JJ-TL)\n",
      "(FACILITY White/JJ-TL)\n",
      "(FACILITY White/JJ-TL)\n",
      "(FACILITY Kremlin/NP)\n",
      "(FACILITY White/JJ-TL)\n",
      "(FACILITY White/JJ-TL)\n",
      "(FACILITY White/JJ-TL House/NN-TL)\n",
      "(FACILITY White/JJ-TL House/NN-TL)\n",
      "(FACILITY Franklin/NP-TL)\n",
      "(FACILITY Kremlin/NP)\n",
      "(FACILITY Franklin/NP-TL Square/NN-TL)\n",
      "(FACILITY Pennsylvania/NP-TL Avenue/NN-TL)\n",
      "(FACILITY Jenks/NP-TL Street/NN-TL)\n",
      "(FACILITY White/JJ-TL)\n",
      "(FACILITY White/JJ-TL)\n",
      "(FACILITY White/JJ-TL)\n",
      "(FACILITY White/JJ-TL)\n",
      "(FACILITY White/JJ-TL)\n",
      "(FACILITY White/JJ-TL)\n",
      "(FACILITY White/JJ-TL)\n",
      "(FACILITY White/JJ-TL House/NN-TL)\n",
      "(FACILITY White/JJ-TL)\n",
      "(FACILITY White/JJ-TL)\n",
      "(FACILITY White/JJ-TL)\n",
      "(FACILITY White/JJ-TL)\n",
      "(FACILITY White/JJ-TL)\n",
      "(FACILITY White/JJ-TL)\n",
      "(FACILITY White/JJ-TL)\n",
      "(FACILITY White/JJ-TL)\n",
      "(FACILITY White/JJ-TL)\n",
      "(FACILITY Pensacola/NP)\n",
      "(FACILITY White/JJ-TL Sox/NPS-TL)\n",
      "(FACILITY Caltech/NP)\n",
      "(FACILITY White/JJ-TL House/NN-TL)\n",
      "(FACILITY White/JJ-TL)\n",
      "(FACILITY Caracas/NP)\n",
      "(FACILITY White/JJ-TL)\n",
      "(FACILITY White/JJ-TL House/NN-TL)\n",
      "(FACILITY White/JJ-TL)\n",
      "(FACILITY White/JJ-TL)\n",
      "(FACILITY White/JJ-TL Way/NN-TL)\n",
      "(FACILITY White/JJ-TL)\n",
      "(FACILITY Kremlin/NP)\n",
      "(FACILITY Kremlin/NP)\n",
      "(FACILITY Madison/NP-TL Square/NN-TL Garden/NN-TL)\n",
      "(FACILITY Boron/NP)\n",
      "(FACILITY Rome/NP)\n",
      "(FACILITY Rome/NP)\n",
      "(FACILITY Grafton/NP)\n",
      "(FACILITY Bari/NP)\n",
      "(FACILITY Bari/NP)\n",
      "(FACILITY Northfield/NP)\n",
      "(FACILITY Baltimore/NP)\n",
      "(FACILITY Hilo/NP)\n",
      "(FACILITY Hilo/NP)\n",
      "(FACILITY White/JJ-TL)\n",
      "(FACILITY White/JJ-TL)\n",
      "(FACILITY White/JJ-TL House/NN-TL)\n",
      "(FACILITY White/JJ-TL House/NN-TL)\n",
      "(FACILITY White/JJ-TL)\n",
      "(FACILITY White/JJ-TL House/NN-TL)\n",
      "(FACILITY White/JJ-TL)\n",
      "(FACILITY White/JJ-TL)\n",
      "(FACILITY White/JJ-TL)\n",
      "(FACILITY White/JJ-TL)\n",
      "(FACILITY White/JJ-TL House/NN-TL)\n",
      "(FACILITY White/JJ-TL House/NN-TL)\n",
      "(FACILITY White/JJ-TL House/NN-TL)\n",
      "(FACILITY White/JJ-TL House/NN-TL)\n",
      "(FACILITY White/JJ-TL)\n",
      "(FACILITY White/JJ-TL)\n",
      "(FACILITY White/JJ-TL)\n",
      "(FACILITY Kremlin/NP)\n",
      "(FACILITY White/JJ-TL House/NN-TL)\n",
      "(FACILITY White/JJ-TL)\n",
      "(FACILITY White/JJ-TL)\n",
      "(FACILITY White/JJ-TL)\n",
      "(FACILITY White/JJ-TL House/NN-TL)\n",
      "(FACILITY White/JJ-TL)\n",
      "(FACILITY White/JJ-TL)\n",
      "(FACILITY White/JJ-TL)\n",
      "(FACILITY White/JJ-TL)\n",
      "(FACILITY White/JJ-TL House/NN-TL)\n",
      "(FACILITY White/JJ-TL)\n",
      "(FACILITY White/JJ-TL)\n",
      "(FACILITY White/JJ-TL)\n",
      "(FACILITY White/JJ-TL)\n",
      "(FACILITY White/JJ-TL House/NN-TL)\n",
      "(FACILITY Whitemarsh/NP)\n",
      "(FACILITY Whitemarsh/NP)\n",
      "(FACILITY Versailles/NP)\n",
      "(FACILITY Marston/NP)\n",
      "(FACILITY Israelite/NP)\n",
      "(FACILITY Whiteleaf/NP)\n",
      "(FACILITY Ninth/OD-TL Street/NN-TL)\n",
      "(FACILITY White/JJ-TL)\n",
      "(FACILITY White/NP)\n",
      "(FACILITY Teheran/NP)\n",
      "(FACILITY Teheran/NP)\n",
      "(FACILITY White/NP)\n",
      "(FACILITY Grafton/NP)\n",
      "(FACILITY Lublin/NP)\n",
      "(FACILITY Winston/NP)\n",
      "(FACILITY Clayton/NP)\n",
      "(FACILITY Penny/NP)\n",
      "(FACILITY Jack/NP)\n",
      "(FACILITY Francie/NP)\n",
      "(FACILITY Phil/NP)\n",
      "(FACILITY White/JJ-TL)\n",
      "(FACILITY Berlin/NP)\n"
     ]
    }
   ],
   "source": [
    "brown = nltk.corpus.brown\n",
    "for sent in brown.tagged_sents():\n",
    "    chunk = nltk.ne_chunk(sent)\n",
    "    for subtree in chunk.subtrees():\n",
    "        if subtree.label() == 'FACILITY': print(subtree)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
